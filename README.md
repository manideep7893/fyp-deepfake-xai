# DeepFake XAI â€“ Explainable Deepfake Detection (Celeb-DF v2)

This project implements an **Explainable AI (XAI) pipeline for deepfake detection**, combining a pretrained Vision Transformer deepfake detector with:

- Grad-CAM visual explanations  
- Region-level attribution analysis  
- Faithfulness evaluation (Insertion / Deletion AUC)  
- Threshold calibration and ROC/PR analysis  

The system is evaluated on the **Celeb-DF (v2)** dataset and designed for **frame-level and face-level explainability**, suitable for academic research and final-year dissertation work.

---

## ðŸŽ¯ Project Motivation

Deepfake detection models often act as black boxes.  
This project addresses two core research questions:

1. Can a pretrained Vision Transformer reliably discriminate real vs fake faces on Celeb-DF?
2. Are its decisions explainable and faithful to manipulated facial regions?

Rather than only reporting accuracy, this project evaluates:

- Discrimination (ROC-AUC, PR-AUC)
- Calibration and threshold stability
- Region-based attribution patterns
- Faithfulness via deletion/insertion curves

This transforms the project from simple model usage into **scientific model evaluation and explainability research**.

---

## ðŸ§  Model

- Base Model: `prithivMLmods/Deep-Fake-Detector-Model`
- Architecture: Vision Transformer (ViT-based)
- Inference: Frame-level, aggregated to video-level

Although the classifier is transformer-based, CNN principles remain central for:

- Face detection
- Spatial localisation
- Grad-CAM heatmap generation
- Faithfulness masking operations

---

## ðŸ” Key Features

### 1ï¸âƒ£ Video Preprocessing
- Frame extraction from videos
- Face detection using YuNet (ONNX)
- Face cropping for consistent model input

### 2ï¸âƒ£ Deepfake Detection
- HuggingFace inference pipeline
- Frame-level probability prediction (`p_fake`)
- Video-level aggregation:
  - Mean probability
  - Median probability
  - Top 10% mean probability

### 3ï¸âƒ£ Explainability (XAI)

- Grad-CAM heatmaps
- MediaPipe-based region attribution:
  - Mouth
  - Eye region
  - Face boundary
- Console-based explanation reports
- Saved heatmap overlays

### 4ï¸âƒ£ Faithfulness Metrics

- Deletion AUC
- Insertion AUC
- Confidence drop analysis

### 5ï¸âƒ£ Scientific Evaluation

- ROC Curve
- PR Curve
- Threshold calibration:
  - Default 0.5
  - Youdenâ€™s J
  - Best F1 threshold
- Frame-level confusion metrics

---

## ðŸ“Š Evaluation Outputs

Running evaluation generates:

```
outputs/eval/
â”œâ”€â”€ frame_level_metrics.json
â”œâ”€â”€ roc_curve.png
â”œâ”€â”€ pr_curve.png
â””â”€â”€ all_frames_combined.csv
```

Metrics include:

- ROC-AUC
- PR-AUC
- Accuracy
- Precision
- Recall (TPR)
- False Positive Rate
- Optimal threshold values

---

## ðŸ“‚ Project Structure

```
deepfake-xai-celebdf/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ video_to_frames.py
â”‚   â”‚   â”œâ”€â”€ extract_faces_from_frames_yunet.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ hf_predict_frames.py
â”‚   â”œâ”€â”€ xai/
â”‚   â”‚   â””â”€â”€ xai_console_report.py
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â””â”€â”€ eval_thresholds.py
â”‚   â””â”€â”€ sanity.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ face_detection_yunet_2023mar.onnx
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ celebdf/
â”‚
â”œâ”€â”€ outputs/         (generated, not tracked)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ðŸš€ How to Run

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Extract Frames

```bash
python src/data/video_to_frames.py \
  --video path/to/video.mp4 \
  --out outputs/frames/sample \
  --every_n 5
```

---

### 3ï¸âƒ£ Extract Faces

```bash
python src/data/extract_faces_from_frames_yunet.py \
  --frames_dir outputs/frames/sample \
  --out_dir outputs/frames_faces/sample \
  --min_face 120 \
  --score_thr 0.9 \
  --margin 0.25
```

---

### 4ï¸âƒ£ Run Detection

```bash
python src/models/hf_predict_frames.py \
  --frames_dir outputs/frames_faces/sample \
  --out_dir outputs/preds/sample \
  --model_id prithivMLmods/Deep-Fake-Detector-Model \
  --device mps
```

---

### 5ï¸âƒ£ Generate XAI Report

```bash
python src/xai/xai_console_report.py \
  --frame outputs/frames_faces/sample/face_00010.jpg \
  --model_id prithivMLmods/Deep-Fake-Detector-Model \
  --device mps \
  --target_class 0 \
  --out_dir outputs/xai/sample
```

---

### 6ï¸âƒ£ Run Full Evaluation

```bash
python src/eval/eval_thresholds.py
```

This computes:

- ROC-AUC
- PR-AUC
- Optimal thresholds
- Frame-level metrics

---

## ðŸ“ˆ Research Contribution

This project goes beyond simple accuracy reporting by:

- Performing threshold calibration analysis
- Evaluating discrimination vs calibration trade-offs
- Analysing decision boundary stability
- Comparing attribution patterns across real and fake samples
- Measuring explanation faithfulness quantitatively

This transforms the system into an **explainable forensic analysis pipeline** rather than a binary classifier.

---

## âš ï¸ Notes

- `outputs/` directory is not tracked in Git.
- Celeb-DF dataset must be downloaded separately.
- The repository contains code only, not dataset files.

---

## ðŸ“š Dataset

- Celeb-DF v2  
- Real and synthesis videos  
- Frame-level face cropping applied before inference  

---

## ðŸ† Academic Context

This repository supports a Final Year Project focused on:

> Explainable Deepfake Detection using Vision Transformers and Faithfulness Evaluation.

The emphasis is on **scientific evaluation, interpretability, and robustness analysis**, rather than model training alone.