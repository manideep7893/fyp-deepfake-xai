# Deepfake Detection with Explainable AI (XAI)

Final Year Project â€“ University of Greenwich

## Project Overview
This project investigates deepfake detection using convolutional neural networks combined with explainable artificial intelligence techniques. The aim is to improve transparency, trust, and ethical accountability by integrating Grad-CAM visual explanations into CNN-based deepfake detection models.

## Objectives
- Examine academic research on deepfake detection and explainable AI
- Identify gaps related to interpretability and user trust
- Implement a CNN-based detection baseline using transfer learning
- Integrate Grad-CAM for visual explanations
- Evaluate both detection performance and explanation quality

## Technologies
- Python
- PyTorch
- OpenCV
- Google Colab
- GitHub
- FaceForensics++ dataset

## Status
Project setup and dataset integration in progress.
